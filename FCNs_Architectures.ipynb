{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "from rasterio.enums import Resampling\n",
    "from PIL import ImageColor\n",
    "from skimage.exposure import rescale_intensity\n",
    "import rasterio as rio\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import ImageColor\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Dropout, MaxPooling2D, Input, concatenate, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from skimage.exposure import rescale_intensity\n",
    "from rasterio.enums import Resampling\n",
    "import rasterio.warp as warp\n",
    "\n",
    "import torch\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import MeanIoU, CategoricalAccuracy, Precision, Recall, AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Localización del data: JSON de clases con paleta de colores, imagen original y su máscara.\n",
    "colores_dir = r'C:\\Users\\Usuari\\Documents\\TFM_Codigos\\MODELO\\data/7Labels.json'\n",
    "colores = json.load(open(colores_dir))\n",
    "colores_df = pd.DataFrame(colores)\n",
    "colores_df[\"values_normalize\"] = colores_df.index\n",
    "colores_df[\"palette\"] = \"#\" + colores_df[\"palette\"]\n",
    "values = colores_df[\"values\"].to_list()\n",
    "values_norm = colores_df[\"values_normalize\"].to_list()\n",
    "palette = colores_df[\"palette\"].to_list()\n",
    "labels = colores_df[\"label\"].to_list()\n",
    "dict_values = {}\n",
    "dict_label = {}\n",
    "dict_palette = {}\n",
    "dict_palette_hex = {}\n",
    "for x in range(0, len(values)):\n",
    "    dict_values[values[x]] = values_norm[x]\n",
    "    dict_label[values_norm[x]] = labels[x]\n",
    "    dict_palette[values_norm[x]] = ImageColor.getrgb(palette[x])\n",
    "    dict_palette_hex[values_norm[x]] = palette[x]\n",
    "cmap = ListedColormap(palette)\n",
    "patches = [\n",
    "    mpatches.Patch(color=palette[i], label=labels[i]) for i in range(len(values))\n",
    "]\n",
    "legend = {\n",
    "    \"handles\": patches,\n",
    "    \"bbox_to_anchor\": (1.05, 1),\n",
    "    \"loc\": 2,\n",
    "    \"borderaxespad\": 0.0,\n",
    "}\n",
    "colores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "def load_and_combine_datasets(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    image_train_pattern = re.compile(r\".npy\") \n",
    "    image_test_pattern = re.compile(r\".npy\")\n",
    "    mascara_train_pattern = re.compile(r\".npy\")\n",
    "    mascara_test_pattern = re.compile(r\".npy\")\n",
    "    \n",
    "    #Almacenar los arrays cargados\n",
    "    image_train_arrays = []\n",
    "    image_test_arrays = []\n",
    "    mascara_train_arrays = []\n",
    "    mascara_test_arrays = []\n",
    "    \n",
    "    for file in files:\n",
    "        if image_train_pattern.match(file):\n",
    "            image_train_arrays.append(np.load(os.path.join(folder_path, file)))\n",
    "        elif image_test_pattern.match(file):\n",
    "            image_test_arrays.append(np.load(os.path.join(folder_path, file)))\n",
    "        elif mascara_train_pattern.match(file):\n",
    "            mascara_train_arrays.append(np.load(os.path.join(folder_path, file)))\n",
    "        elif mascara_test_pattern.match(file):\n",
    "            mascara_test_arrays.append(np.load(os.path.join(folder_path, file)))\n",
    "    combined_images_train = np.concatenate(image_train_arrays, axis=0)\n",
    "    combined_images_test = np.concatenate(image_test_arrays, axis=0)\n",
    "    combined_mascara_train = np.concatenate(mascara_train_arrays, axis=0)\n",
    "    combined_mascara_test = np.concatenate(mascara_test_arrays, axis=0)\n",
    "    \n",
    "    return combined_images_train, combined_images_test, combined_mascara_train, combined_mascara_test\n",
    "\n",
    "folder_path = r\"C:\\Users\\Usuari\\Documents\\TFM_Codigos\\DATASET\\Data-arrays\"\n",
    "images_train, images_test, mascara_train, mascara_test = load_and_combine_datasets(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mascara_train_category = to_categorical(mascara_train)\n",
    "mascara_test_category = to_categorical(mascara_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red FCN_ResNet50_Javi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FCN_ResNet50(input_shape, num_classes):\n",
    "    # Usar ResNet50V2 como backbone\n",
    "    base_model = tf.keras.applications.ResNet50V2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    layer_names = [\n",
    "        'conv2_block3_out',   \n",
    "        'conv3_block4_out',   \n",
    "        'conv4_block6_out',   \n",
    "    ]\n",
    "    layer_outputs = [base_model.get_layer(name).output for name in layer_names]\n",
    "    down_stack = tf.keras.Model(inputs=base_model.input, outputs=layer_outputs)\n",
    "    down_stack.trainable = False\n",
    "    x = layers.Conv2D(256, (1, 1), padding='same', activation='relu')(down_stack.output[-2])  # 8×8 \n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    # Decodificador \n",
    "    x = layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)  # 8×8 → 16×16\n",
    "    skip_2 = layers.Conv2D(128, (1, 1), padding='same', activation='relu')(down_stack.outputs[1]) \n",
    "    x = Concatenate()([x, skip_2])\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)   # 16×16 → 32×32\n",
    "    skip_1 = layers.Conv2D(64, (1, 1), padding='same', activation='relu')(down_stack.outputs[0])  \n",
    "    x = Concatenate()([x, skip_1])\n",
    "    x = layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)   # 32×32 → 64×64\n",
    "    x = layers.Conv2DTranspose(16, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)   # 64×64 → 128×128\n",
    "    # Salida final\n",
    "    x = layers.Conv2D(num_classes, (1, 1), padding='same', activation='softmax')(x)  # (128×128×7)\n",
    "\n",
    "    model = tf.keras.Model(inputs=down_stack.input, outputs=x)\n",
    "    for i, layer_output in enumerate(down_stack.outputs):\n",
    "        print(f\"Salida {i}: {layer_output.shape}\")\n",
    "    return model\n",
    "\n",
    "# Parámetros del modelo\n",
    "input_shape = (128, 128, 3)  # Tamaño de las imágenes\n",
    "num_classes = 7  # Número de clases\n",
    "\n",
    "model = FCN_ResNet50(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red MobileNetV2_Javi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FCN_MobileNetV2(input_shape, num_classes):\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    \n",
    "    layer_names = [\n",
    "        'block_1_expand_relu',   \n",
    "        'block_3_expand_relu',  \n",
    "        'block_6_expand_relu',  \n",
    "    ]\n",
    "    layer_outputs = [base_model.get_layer(name).output for name in layer_names]\n",
    "    down_stack = tf.keras.Model(inputs=base_model.input, outputs=layer_outputs)\n",
    "    down_stack.trainable = False\n",
    "    x = layers.Conv2D(256, (3, 3), strides=2, padding='same', activation='relu')(down_stack.output[-1])  # 8×8 \n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    # Decodificador\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)  # 8×8 → 16×16\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)   # 16×16 → 32×32\n",
    "    x = layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)   # 32×32 → 64×64\n",
    "    x = layers.Conv2DTranspose(16, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)   # 64×64 → 128×128\n",
    "    # Salida final\n",
    "    x = layers.Conv2D(num_classes, (1, 1), padding='same', activation='softmax')(x)  # (128×128×7) Volvemos a la forma original\n",
    "    # Crear el modelo final\n",
    "    model = tf.keras.Model(inputs=down_stack.input, outputs=x)\n",
    "    for i, layer_output in enumerate(down_stack.outputs):\n",
    "        print(f\"Salida {i}: {layer_output.shape}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "input_shape = (128, 128, 3)  # Tamaño de las imágenes\n",
    "num_classes = 7  # Número de clases\n",
    "\n",
    "\n",
    "model = FCN_MobileNetV2(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilar el modelo\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss=CategoricalCrossentropy(),\n",
    "    metrics=[MeanIoU(num_classes=num_classes), CategoricalAccuracy(), Precision(), Recall(), AUC()]\n",
    ")\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=5)\n",
    "]\n",
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    x=images_train,\n",
    "    y=mascara_train_category,\n",
    "    batch_size=16,  # Aumentar el batch size\n",
    "    epochs=35,\n",
    "    validation_data=(images_test, mascara_test_category),\n",
    "    callbacks=callbacks,\n",
    "    shuffle=True,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('FCN_rESnEt50_v0.keras')\n",
    "#model.save('FCN_MobileNet_v0.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis de los resultados + gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Número de imágenes ráster a mostrar\n",
    "num_samples = 10\n",
    "indices = np.random.choice(len(images_test), num_samples, replace=False)\n",
    "\n",
    "plt.figure(figsize=(12, num_samples * 3))\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    img = images_test[idx]\n",
    "    true_mask = mascara_test[idx]  # Máscara real\n",
    "\n",
    "    # Predecir la máscara\n",
    "    pred_mask = model.predict(img[np.newaxis, ...])  \n",
    "    pred_mask = np.argmax(pred_mask, axis=-1)[0] \n",
    "\n",
    "    # Mostrar la imagen original\n",
    "    plt.subplot(num_samples, 3, i * 3 + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Imagen original\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    \n",
    "    plt.subplot(num_samples, 3, i * 3 + 2)\n",
    "    plt.imshow(true_mask, cmap=cmap, vmin=0, vmax=len(palette) - 1)  \n",
    "    plt.title(\"Ground truth\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(num_samples, 3, i * 3 + 3)\n",
    "    plt.imshow(pred_mask, cmap=cmap, vmin=0, vmax=len(palette) - 1) \n",
    "    plt.title(\"Predicción\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2, 5))\n",
    "ax.legend(**legend)\n",
    "ax.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los valores del historial\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "iou = history.history['mean_io_u']  \n",
    "val_iou = history.history['val_mean_io_u']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, loss, 'bo-', label='Entrenamiento')\n",
    "plt.plot(epochs, val_loss, 'ro-', label='Validación')\n",
    "plt.title('Pérdida durante el entrenamiento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "y_pred = model.predict(images_test)  \n",
    "y_pred = np.argmax(y_pred, axis=-1)  \n",
    "y_true = np.argmax(mascara_test_category, axis=-1)  \n",
    "y_true_flat = y_true.flatten()\n",
    "y_pred_flat = y_pred.flatten()\n",
    "\n",
    "# Calcular precisión, recall y F1-score por clase\n",
    "precision = precision_score(y_true_flat, y_pred_flat, average=None)  \n",
    "recall = recall_score(y_true_flat, y_pred_flat, average=None) \n",
    "f1 = f1_score(y_true_flat, y_pred_flat, average=None) \n",
    "for i, f1_value in enumerate(f1):\n",
    "    print(f\"Clase {i}: F1-score = {f1_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = model.predict(images_test)  \n",
    "y_pred = np.argmax(y_pred, axis=-1)  \n",
    "y_true = np.argmax(mascara_test_category, axis=-1)  \n",
    "y_true_flat = y_true.flatten()\n",
    "y_pred_flat = y_pred.flatten()\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "cm = confusion_matrix(y_true_flat, y_pred_flat, labels=np.arange(num_classes))\n",
    "\n",
    "# Crear un gráfico con la matriz de confusión\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Verdadero')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar la matriz de confusión (entre 0 y 1)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', xticklabels=labels, yticklabels=labels, cbar_kws={'label': 'Frecuencia Relativa'})\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "history_dict = history.history\n",
    "# Extraer las métricas\n",
    "epochs = range(1, len(history_dict['loss']) + 1)\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "iou = history_dict.get('mean_io_u', None)\n",
    "val_iou = history_dict.get('val_mean_io_u', None)  \n",
    "data = {\n",
    "    'Epoch': epochs,\n",
    "    'Loss': loss,\n",
    "    'Validation Loss': val_loss,\n",
    "    'Mean IoU': iou,\n",
    "    'Validation Mean IoU': val_iou\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('training_metrics.csv', index=False)\n",
    "f1_scores = pd.DataFrame({\n",
    "    'Class': labels,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1\n",
    "})\n",
    "\n",
    "# Guardar los F1 Scores en un archivo CSV\n",
    "f1_scores.to_csv('f1_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráficas del rendimiento del modelo durante aprendizaje\n",
    "history = pd.DataFrame(history.history)\n",
    "print(history)\n",
    "\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.plot(range(len(history['categorical_accuracy'].values.tolist())), history['categorical_accuracy'].values.tolist(), label = 'Train_Accuracy')\n",
    "plt.plot(range(len(history['loss'].values.tolist())), history['loss'].values.tolist(), label = 'Train_Loss')\n",
    "plt.plot(range(len(history['val_categorical_accuracy'].values.tolist())), history['val_categorical_accuracy'].values.tolist(), label = 'Test_Accuracy')\n",
    "plt.plot(range(len(history['val_loss'].values.tolist())), history['val_loss'].values.tolist(), label = 'Test_Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
