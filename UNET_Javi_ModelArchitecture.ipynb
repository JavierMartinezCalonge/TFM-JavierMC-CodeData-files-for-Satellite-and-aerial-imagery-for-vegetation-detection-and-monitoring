{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "from rasterio.enums import Resampling\n",
    "from PIL import ImageColor\n",
    "from skimage.exposure import rescale_intensity\n",
    "import rasterio as rio\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import ImageColor\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Dropout, MaxPooling2D, Input, concatenate\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.metrics import MeanIoU, CategoricalAccuracy, Precision, Recall, AUC\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report \n",
    "from skimage.exposure import rescale_intensity\n",
    "from rasterio.enums import Resampling\n",
    "import rasterio.warp as warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of data\n",
    "lc_dir = r'C:\\Users\\Usuari\\Documents\\TFM_Codigos\\MODELO\\data/7Labels.json'\n",
    "# Load Land Cover Parameter\n",
    "lc = json.load(open(lc_dir))\n",
    "lc_df = pd.DataFrame(lc)\n",
    "lc_df[\"values_normalize\"] = lc_df.index #+ 1\n",
    "lc_df[\"palette\"] = \"#\" + lc_df[\"palette\"]\n",
    "\n",
    "# Mapping from old to new values\n",
    "values = lc_df[\"values\"].to_list()\n",
    "values_norm = lc_df[\"values_normalize\"].to_list()\n",
    "palette = lc_df[\"palette\"].to_list()\n",
    "labels = lc_df[\"label\"].to_list()\n",
    "dict_values = {}\n",
    "dict_label = {}\n",
    "dict_palette = {}\n",
    "dict_palette_hex = {}\n",
    "for x in range(0, len(values)):\n",
    "    dict_values[values[x]] = values_norm[x]\n",
    "    dict_label[values_norm[x]] = labels[x]\n",
    "    dict_palette[values_norm[x]] = ImageColor.getrgb(palette[x])\n",
    "    dict_palette_hex[values_norm[x]] = palette[x]\n",
    "\n",
    "# Create colormap from values and palette\n",
    "cmap = ListedColormap(palette)\n",
    "\n",
    "# Patches legend\n",
    "patches = [\n",
    "    mpatches.Patch(color=palette[i], label=labels[i]) for i in range(len(values))\n",
    "]\n",
    "legend = {\n",
    "    \"handles\": patches,\n",
    "    \"bbox_to_anchor\": (1.05, 1),\n",
    "    \"loc\": 2,\n",
    "    \"borderaxespad\": 0.0,\n",
    "}\n",
    "lc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "def load_and_combine_datasets(folder_path):\n",
    "    # Listar todos los archivos en la carpeta\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    # Expresiones regulares para identificar los archivos\n",
    "    image_train_pattern = re.compile(r\"images_train_PNOA_(\\d+)\\.npy\")\n",
    "    image_test_pattern = re.compile(r\"images_test_PNOA_(\\d+)\\.npy\")\n",
    "    lcs_train_pattern = re.compile(r\"lcs_train_PNOA_(\\d+)\\.npy\")\n",
    "    lcs_test_pattern = re.compile(r\"lcs_test_PNOA_(\\d+)\\.npy\")\n",
    "    \n",
    "    # Diccionarios para almacenar los arrays cargados\n",
    "    image_train_arrays = []\n",
    "    image_test_arrays = []\n",
    "    lcs_train_arrays = []\n",
    "    lcs_test_arrays = []\n",
    "    \n",
    "    # Recorrer todos los archivos en la carpeta\n",
    "    for file in files:\n",
    "        # Cargar y clasificar los archivos según su tipo\n",
    "        if image_train_pattern.match(file):\n",
    "            image_train_arrays.append(np.load(os.path.join(folder_path, file)))\n",
    "        elif image_test_pattern.match(file):\n",
    "            image_test_arrays.append(np.load(os.path.join(folder_path, file)))\n",
    "        elif lcs_train_pattern.match(file):\n",
    "            lcs_train_arrays.append(np.load(os.path.join(folder_path, file)))\n",
    "        elif lcs_test_pattern.match(file):\n",
    "            lcs_test_arrays.append(np.load(os.path.join(folder_path, file)))\n",
    "    \n",
    "    # Combinar los arrays de cada categoría\n",
    "    combined_images_train = np.concatenate(image_train_arrays, axis=0)\n",
    "    combined_images_test = np.concatenate(image_test_arrays, axis=0)\n",
    "    combined_lcs_train = np.concatenate(lcs_train_arrays, axis=0)\n",
    "    combined_lcs_test = np.concatenate(lcs_test_arrays, axis=0)\n",
    "    \n",
    "    return combined_images_train, combined_images_test, combined_lcs_train, combined_lcs_test\n",
    "\n",
    "# Uso de la función\n",
    "folder_path = r\"C:\\Users\\Usuari\\Documents\\TFM_Codigos\\DATASET\\Data-arrays\"\n",
    "# Cambia esto por la ruta a tu carpeta\n",
    "images_train, images_test, lcs_train, lcs_test = load_and_combine_datasets(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train_predictors_shape: {images_train.shape}\\nTrain_label_shape: {lcs_train.shape}\\nTest_predictors_shape: {images_test.shape}\\nTest_label_shape: {lcs_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make lcs data into categorical\n",
    "# Keras model use different output data shape for category data\n",
    "# Convert it using utility from keras to make into categorical shape\n",
    "lcs_train_category = to_categorical(lcs_train)\n",
    "lcs_test_category = to_categorical(lcs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lcs_test_category.shape)\n",
    "print(lcs_train_category.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make keras model\n",
    "input_shape = images_train.shape\n",
    "input_shape = (input_shape[1], input_shape[2], input_shape[3])\n",
    "num_classes = 7\n",
    "\n",
    "neuron = 64\n",
    "kernel = 3\n",
    "kernel_t = 2\n",
    "dropout = 0.2\n",
    "strides = 2\n",
    "pool = 2\n",
    "padding = 'same'\n",
    "\n",
    "input_layer = Input(input_shape)\n",
    "\n",
    "def conv2_block(input, neuron, last=False):\n",
    "\tconv1 = Conv2D(neuron, kernel, activation='relu', padding=padding)(input)\n",
    "\tconv2 = Conv2D(neuron, kernel, activation='relu', padding=padding)(conv1)\n",
    "\treturn conv2\n",
    "\n",
    "def encode(input, neuron):\n",
    "\tconv1 = conv2_block(input, neuron)\n",
    "\tmp = MaxPooling2D(2)(conv1)\n",
    "\tdp = Dropout(dropout)(mp)\n",
    "\treturn conv1, dp\n",
    "\n",
    "def decode(input, conv, neuron):\n",
    "\tconv_t = Conv2DTranspose(neuron, kernel_t, strides, activation='relu', padding=padding)(input)\n",
    "\tconcat = concatenate([conv_t, conv])\n",
    "\tconv2 = conv2_block(concat, neuron)\n",
    "\tdp = Dropout(dropout)(conv2)\n",
    "\treturn dp\n",
    "\n",
    "conv1, mp1 = encode(input_layer, neuron * 1)\n",
    "conv2, mp2 = encode(mp1, neuron * 2)\n",
    "conv3, mp3 = encode(mp2, neuron * 4)\n",
    "conv4, mp4 = encode(mp3, neuron * 8)\n",
    "\n",
    "transition = conv2_block(mp4, neuron * 16)\n",
    "\n",
    "uncov1 = decode(transition, conv4, neuron * 8)\n",
    "uncov2 = decode(uncov1, conv3, neuron * 4)\n",
    "uncov3 = decode(uncov2, conv2, neuron * 2)\n",
    "uncov4 = decode(uncov3, conv1, neuron * 1)\n",
    "\n",
    "output = Conv2D(lcs_train_category.shape[3], 1, padding=padding, activation='softmax')(uncov4)\n",
    "\n",
    "model = Model(input_layer, output)\n",
    "model.summary()\n",
    "mascaras_train_category = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "\toptimizer=keras.optimizers.Adam(0.001),  \n",
    "\tloss=keras.losses.CategoricalCrossentropy(),\n",
    "\tmetrics=[keras.metrics.CategoricalAccuracy(), keras.metrics.MeanIoU(num_classes=num_classes), Recall(), Precision()\t\n",
    "])\n",
    "callbacks = [\n",
    "\tEarlyStopping(patience=5, monitor='categorical_accuracy', restore_best_weights=True)\n",
    "]\n",
    "result = model.fit(\n",
    "\tx=images_train,\n",
    "\ty=mascaras_train_category,\n",
    "\tepochs= 35, #100\n",
    "\tbatch_size= 8, #16\n",
    "\tshuffle=True,\n",
    "\tvalidation_split=0.2,\n",
    "\tcallbacks=callbacks,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show history\n",
    "history = pd.DataFrame(result.history)\n",
    "print(history)\n",
    "\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.plot(range(len(history['categorical_accuracy'].values.tolist())), history['categorical_accuracy'].values.tolist(), label = 'Train_Accuracy')\n",
    "plt.plot(range(len(history['loss'].values.tolist())), history['loss'].values.tolist(), label = 'Train_Loss')\n",
    "plt.plot(range(len(history['val_categorical_accuracy'].values.tolist())), history['val_categorical_accuracy'].values.tolist(), label = 'Test_Accuracy')\n",
    "plt.plot(range(len(history['val_loss'].values.tolist())), history['val_loss'].values.tolist(), label = 'Test_Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test data\n",
    "prediction = np.argmax(model.predict(images_test), 3).flatten()\n",
    "label = lcs_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Obtener las predicciones del modelo\n",
    "y_pred = model.predict(images_test)  # (N, 128, 128, num_classes)\n",
    "y_pred = np.argmax(y_pred, axis=-1)  # Convertir a etiquetas de clase (N, 128, 128)\n",
    "\n",
    "# Obtener las máscaras verdaderas (ground truth)\n",
    "y_true = np.argmax(lcs_test_category, axis=-1)  # Convertir one-hot a etiquetas (N, 128, 128)\n",
    "\n",
    "# Aplanar las predicciones y las etiquetas verdaderas para la matriz de confusión\n",
    "y_true_flat = y_true.flatten()\n",
    "y_pred_flat = y_pred.flatten()\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "cm = confusion_matrix(y_true_flat, y_pred_flat, labels=np.arange(num_classes))\n",
    "\n",
    "# Crear un gráfico con la matriz de confusión\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Verdadero')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar la matriz de confusión (entre 0 y 1)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Visualización de la matriz normalizada\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', xticklabels=labels, yticklabels=labels, cbar_kws={'label': 'Frecuencia Relativa'})\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(label, prediction, normalize='true')\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "cm = ConfusionMatrixDisplay(cm)\n",
    "cm.plot(ax = ax)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_non_augment_size = int(len(images_test) / 8)\n",
    "\n",
    "plt.figure(figsize=(8, image_non_augment_size * 2))\n",
    "\n",
    "# Apply to classified image of the image\n",
    "for x in range(0, image_non_augment_size - 1):\n",
    "\tindex = x * 8\n",
    "\n",
    "\timage = images_test[index:(index + 1)]\n",
    "\tpred = model.predict(image)\n",
    "\tpred = np.argmax(pred, 3)[0]\n",
    "\n",
    "\tplt.subplot(image_non_augment_size, 3, x * 3 + 1)\n",
    "\tplt.imshow(image[0])\n",
    "\n",
    "\tplt.subplot(image_non_augment_size, 3, x * 3 + 2)\n",
    "\tplt.imshow(lcs_test[index], cmap=cmap, interpolation='nearest', vmin=0, vmax=6)\n",
    "\n",
    "\tplt.subplot(image_non_augment_size, 3, x * 3 + 3)\n",
    "\tplt.imshow(pred, cmap=cmap, interpolation='nearest', vmin=0, vmax=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('UNET40_7L_Javi_v03042025.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
